import pandas as pd
import numpy as np
import os
import time
import random
import requests
import PyPDF2
import urllib.request # For downloading files from url
from bs4 import BeautifulSoup

import warnings
warnings.filterwarnings("ignore")

os.chdir('/Users/Alia/Documents/Github/FinalProjectPPOL564/Raw_Data/LI_Heaters')
li_store = '/Users/Alia/Documents/Github/FinalProjectPPOL564/Raw_Data/LI_Heaters'

full_df = pd.DataFrame(columns=['State',
                                'Year',
                                'State_Year',
                                'LI_Coal_Heaters',
                                'LI_NG_Heaters',
                                'LI_FO_KE_Heaters',
                                'LI_LPG_Heaters',
                                'LI_EL_Heaters',
                                'LI_Wood_Heaters'])

# Loop through .txt file
for f_name in os.listdir(li_store):
    # Check that all are .txt
    if f_name.endswith('.xlsx'):
        # Pull year from file name
        year = f_name.split('Heaters_',1)[1].split('.xlsx')[0]
        # Read in .txt as fixed with file, skipping header
        df = pd.read_excel(f_name)
        # Limit to only states and DC
        df = df.replace(["Dist. of Col."],"District of Columbia")
        df['State'] = df['State'].str.upper()
        # Add year column
        df.insert(1,'Year',year)
        df.insert(2,'State_Year',df['State'] + ' ' + df['Year'])
        # Add year data to full df
        full_df = full_df.append(df,ignore_index=True)
        full_df = full_df.sort_values(["State","Year"],ascending = (True,True))
        full_df = full_df.reset_index(drop=True)

# Store as .csv file
os.chdir('/Users/Alia/Documents/Github/FinalProjectPPOL564/Clean_Data')
full_df.to_csv('LI_Heaters.csv',index = False, header=True)

###_____________________________________________________________________________________________________

os.chdir('/Users/Alia/Documents/Github/FinalProjectPPOL564/Raw_Data')
cons = pd.read_csv('Energy_Consumption.csv')
exp = pd.read_csv('Energy_Expenditure.csv')
prices = pd.read_csv('Energy_Prices.csv')
codes = pd.read_csv('Codes.csv')

cols = ['State','Year','State_Year']
for name in codes['Variable Name'].tolist():
    cols.append(name)

full_df = pd.DataFrame(columns=cols)

us_state_to_abbrev = {
    "Alabama": "AL",
    "Alaska": "AK",
    "Arizona": "AZ",
    "Arkansas": "AR",
    "California": "CA",
    "Colorado": "CO",
    "Connecticut": "CT",
    "Delaware": "DE",
    "District of Columbia":"DC",
    "Florida": "FL",
    "Georgia": "GA",
    "Hawaii": "HI",
    "Idaho": "ID",
    "Illinois": "IL",
    "Indiana": "IN",
    "Iowa": "IA",
    "Kansas": "KS",
    "Kentucky": "KY",
    "Louisiana": "LA",
    "Maine": "ME",
    "Maryland": "MD",
    "Massachusetts": "MA",
    "Michigan": "MI",
    "Minnesota": "MN",
    "Mississippi": "MS",
    "Missouri": "MO",
    "Montana": "MT",
    "Nebraska": "NE",
    "Nevada": "NV",
    "New Hampshire": "NH",
    "New Jersey": "NJ",
    "New Mexico": "NM",
    "New York": "NY",
    "North Carolina": "NC",
    "North Dakota": "ND",
    "Ohio": "OH",
    "Oklahoma": "OK",
    "Oregon": "OR",
    "Pennsylvania": "PA",
    "Rhode Island": "RI",
    "South Carolina": "SC",
    "South Dakota": "SD",
    "Tennessee": "TN",
    "Texas": "TX",
    "Utah": "UT",
    "Vermont": "VT",
    "Virginia": "VA",
    "Washington": "WA",
    "West Virginia": "WV",
    "Wisconsin": "WI",
    "Wyoming": "WY",
    "District of Columbia": "DC",
    "American Samoa": "AS",
    "Guam": "GU",
    "Northern Mariana Islands": "MP",
    "Puerto Rico": "PR",
    "United States Minor Outlying Islands": "UM",
    "U.S. Virgin Islands": "VI",
}

# Invert the dictionary
abbrev_to_us_state = dict(map(reversed, us_state_to_abbrev.items()))

for sheet in [cons,exp,prices]:
    sheet['State'] = sheet['State'].map(abbrev_to_us_state)

codes_lookup = codes.iloc[:, 0:2]
codes_dict  = dict(codes_lookup.values)

cons
